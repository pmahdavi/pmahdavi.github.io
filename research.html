<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research - Pouria Mahdavinia</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <a href="index.html" class="nav-logo">Pouria Mahdavinia</a>
            <ul class="nav-menu">
                <li><a href="index.html" class="nav-link">About</a></li>
                <li><a href="research.html" class="nav-link active">Research</a></li>
                <li><a href="blog.html" class="nav-link">Blog</a></li>
                <li><a href="https://docs.google.com/document/d/1fe7C0EIEZW5hIzsctwok-RH9MTGKWt2ogtwMjXjE60Y/edit?usp=sharing" class="nav-link" target="_blank">CV</a></li>
            </ul>
        </div>
    </nav>

    <main class="container">
        <h1>Research</h1>
        <p class="page-description">My research focuses on memory-efficient training methods and model merging, grounded in a deep understanding of optimization theory and its evolution. More recently, I've also been working on Mathematics and Informatics Olympiadâ€“level benchmarks for evaluating LLMs' reasoning on complex problems.</p>

        <section class="research-section">
            <article class="paper">
                <h3><a href="https://huggingface.co/papers/2509.11167">Harnessing Optimization Dynamics for Curvature-Informed Model Merging</a></h3>
                <p class="authors"><strong>Pouria Mahdavinia</strong>, Hamed Mahdavi, Niloofar Mireshghallah, Mehrdad Mahdavi</p>
                <p class="venue">Under review</p>
                <p class="description">Benchmarked capability-based model merging for post-training at 8B scale. Leveraged this benchmark to study why model merging works and how it can be improved in this setting. Proposed a novel task-vector pruning method called Fast-Fisher-Grafting (FFG) and showed it's critical for merging performance. Integrated all findings into a new model merging algorithm: the OTA framework.</p>
                <div class="paper-links">
                    <a href="https://huggingface.co/papers/2509.11167" class="paper-link">Paper</a>
                    <a href="https://github.com/pmahdavi/ota-merge" class="paper-link">Code</a>
                </div>
            </article>

            <article class="paper">
                <h3><a href="https://openreview.net/pdf?id=W3D3TVo9a3">Low-rank Momentum Factorization for Memory Efficient Training</a></h3>
                <p class="authors"><strong>Pouria Mahdavinia</strong>, Mehrdad Mahdavi</p>
                <p class="venue">TMLR 2025 (Awarded J2C Certification)</p>
                <p class="description">Developed MoFaSGD, the first memory-efficient Muon optimizer variant, achieving consistent and high throughput gains compared to other memory-efficient optimizers while maintaining LoRA-like GPU memory usage compared to Muon. Validated on NanoGPT and Allen AI's Tulu3-SFT replication at 8B parameter scale. The core idea is to keep momentum on a low-rank manifold using a low-rank factorized representation of the full-rank momentum matrix.</p>
                <div class="paper-links">
                    <a href="https://openreview.net/pdf?id=W3D3TVo9a3" class="paper-link">Paper</a>
                    <a href="https://github.com/pmahdavi/MoFaSGD" class="paper-link">Code</a>
                </div>
            </article>

            <article class="paper">
                <h3><a href="https://arxiv.org/pdf/2510.09021">Refgrader: Automated Grading Of Mathematical Competition Proofs Using Agentic Workflows</a></h3>
                <p class="authors">Hamed Mahdavi, <strong>Pouria Mahdavinia</strong>, Samira Malek, Pegah Mohammadipour, Alireza Hashemi, Majid Daliri, Alireza Farhadi, Amir Khasahmadi, Niloofar Mireshghallah, Vasant Honavar</p>
                <p class="venue">MATH-AI NeurIPS 2025</p>
                <p class="description">Worked on a benchmark evaluating frontier LLMs on multi-level IMO proof grading and helped design agentic systems that outperformed single-turn approaches.</p>
                <div class="paper-links">
                    <a href="https://arxiv.org/pdf/2510.09021" class="paper-link">Paper</a>
                    <a href="https://github.com/ref-grader/ref-grader" class="paper-link">Code</a>
                </div>
            </article>

            <article class="paper">
                <h3><a href="https://arxiv.org/pdf/2510.27094">CombiGraph-Vis: A Curated Multimodal Olympiad Benchmark for Discrete Mathematical Reasoning</a></h3>
                <p class="authors">Hamed Mahdavi, <strong>Pouria Mahdavinia</strong>, Alireza Farhadi, Pegah Mohammadipour, Samira Malek, Pedram Mohammadipour, Majid Daliri, Alireza Hashemi, Amir Khasahmadi, Vasant G Honavar</p>
                <p class="venue">MATH-AI NeurIPS 2025</p>
                <p class="description">Worked on evaluating frontier open- and closed-source LLMs on multimodal problems at the Informatics Olympiad level by sourcing and curating Iranian Informatics Olympiad problems and solutions.</p>
                <div class="paper-links">
                    <a href="https://arxiv.org/pdf/2510.27094" class="paper-link">Paper</a>
                    <a href="https://github.com/pmahdavi/inoi-prime" class="paper-link">Code</a>
                </div>
            </article>

            <article class="paper">
                <h3><a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/dfee09496a5a8b0b01d9d4c589758832-Abstract-Conference.html">Distributed personalized empirical risk minimization</a></h3>
                <p class="authors">Yuyang Deng, Mohammad Mahdi Kamani, <strong>Pouria Mahdavinia</strong>, Mehrdad Mahdavi</p>
                <p class="venue">NeurIPS 2023</p>
                <div class="paper-links">
                    <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/dfee09496a5a8b0b01d9d4c589758832-Abstract-Conference.html" class="paper-link">Paper</a>
                </div>
            </article>

            <article class="paper">
                <h3><a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/ca4f6e86453e4b117dd3263792053cf5-Abstract-Conference.html">Tight Analysis of Extra-gradient and Optimistic Gradient Methods For Nonconvex Minimax Problems</a></h3>
                <p class="authors"><strong>Pouria Mahdavinia</strong>, Yuyang Deng, Haochuan Li, Mehrdad Mahdavi</p>
                <p class="venue">NeurIPS 2022</p>
                <div class="paper-links">
                    <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/ca4f6e86453e4b117dd3263792053cf5-Abstract-Conference.html" class="paper-link">Paper</a>
                </div>
            </article>
        </section>
    </main>

    <footer>
        <p>&copy; 2025 Pouria Mahdavinia. All rights reserved.</p>
    </footer>
</body>
</html>
